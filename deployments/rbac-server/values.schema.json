{"$schema":"http://json-schema.org/draft-07/schema#","$ref":"#/$defs/helm-values","$defs":{"helm-values":{"type":"object","properties":{"affinity":{"$ref":"#/$defs/helm-values.affinity"},"cache":{"$ref":"#/$defs/helm-values.cache"},"enable":{"$ref":"#/$defs/helm-values.enable"},"enablePrometheusRule":{"$ref":"#/$defs/helm-values.enablePrometheusRule"},"enableServiceMonitor":{"$ref":"#/$defs/helm-values.enableServiceMonitor"},"fullnameOverride":{"$ref":"#/$defs/helm-values.fullnameOverride"},"global":{"$ref":"#/$defs/helm-values.global"},"image":{"$ref":"#/$defs/helm-values.image"},"internalGrpcPort":{"$ref":"#/$defs/helm-values.internalGrpcPort"},"livenessProbe":{"$ref":"#/$defs/helm-values.livenessProbe"},"monitoringPort":{"$ref":"#/$defs/helm-values.monitoringPort"},"nameOverride":{"$ref":"#/$defs/helm-values.nameOverride"},"nodeSelector":{"$ref":"#/$defs/helm-values.nodeSelector"},"podAnnotations":{"$ref":"#/$defs/helm-values.podAnnotations"},"podSecurityContext":{"$ref":"#/$defs/helm-values.podSecurityContext"},"replicaCount":{"$ref":"#/$defs/helm-values.replicaCount"},"resources":{"$ref":"#/$defs/helm-values.resources"},"roleScopesMap":{"$ref":"#/$defs/helm-values.roleScopesMap"},"securityContext":{"$ref":"#/$defs/helm-values.securityContext"},"tolerations":{"$ref":"#/$defs/helm-values.tolerations"},"version":{"$ref":"#/$defs/helm-values.version"},"volumeMounts":{"$ref":"#/$defs/helm-values.volumeMounts"},"volumes":{"$ref":"#/$defs/helm-values.volumes"}},"additionalProperties":false},"helm-values.affinity":{"description":"A Kubernetes Affinity, if required.\nFor more information, see [Assigning Pods to Nodes](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node).\n\nFor example:\naffinity:\n  nodeAffinity:\n   requiredDuringSchedulingIgnoredDuringExecution:\n     nodeSelectorTerms:\n     - matchExpressions:\n       - key: foo.bar.com/role\n         operator: In\n         values:\n         - master","type":"object"},"helm-values.cache":{"type":"object","properties":{"clusterManagerServerInternalAddr":{"$ref":"#/$defs/helm-values.cache.clusterManagerServerInternalAddr"},"syncInterval":{"$ref":"#/$defs/helm-values.cache.syncInterval"},"userManagerServerInternalAddr":{"$ref":"#/$defs/helm-values.cache.userManagerServerInternalAddr"}},"additionalProperties":false},"helm-values.cache.clusterManagerServerInternalAddr":{"description":"The address of the cluster-manager-server to call cluster APIs for data sync.","type":"string","default":"cluster-manager-server-internal-grpc:8083"},"helm-values.cache.syncInterval":{"description":"The interval time for cache synchronization.","type":"string","default":"10s"},"helm-values.cache.userManagerServerInternalAddr":{"description":"The address of the user-manager-server to call user APIs for data sync.","type":"string","default":"user-manager-server-internal-grpc:8082"},"helm-values.enable":{"description":"This field can be used as a condition when using it as a dependency. This definition is only here as a placeholder such that it is included in the json schema.","type":"boolean"},"helm-values.enablePrometheusRule":{"description":"If enabled, a `PrometheusRule` resource is created, which is used to define a alert rule for the Prometheus. NOTE: To use this feature, prometheus-operator must be installed in advance.","type":"boolean","default":false},"helm-values.enableServiceMonitor":{"description":"If enabled, a `ServiceMonitor` resource is created, which is used to define a scrape target for the Prometheus. NOTE: To use this feature, prometheus-operator must be installed in advance.","type":"boolean","default":false},"helm-values.fullnameOverride":{"description":"Override the \"rbac-server.fullname\" value. This value is used as part of most of the names of the resources created by this Helm chart.","type":"string"},"helm-values.global":{"description":"Global values shared across all (sub)charts","type":"object","properties":{"auth":{"$ref":"#/$defs/helm-values.global.auth"}}},"helm-values.global.auth":{"type":"object","properties":{"dexServerAddr":{"$ref":"#/$defs/helm-values.global.auth.dexServerAddr"}}},"helm-values.global.auth.dexServerAddr":{"description":"The address of the dex-server to verify a token.","type":"string","default":"dex-server-http:5556"},"helm-values.image":{"type":"object","properties":{"pullPolicy":{"$ref":"#/$defs/helm-values.image.pullPolicy"},"repository":{"$ref":"#/$defs/helm-values.image.repository"}},"additionalProperties":false},"helm-values.image.pullPolicy":{"description":"Kubernetes imagePullPolicy on Deployment.","type":"string","default":"IfNotPresent"},"helm-values.image.repository":{"description":"The container image name.","type":"string","default":"public.ecr.aws/cloudnatix/llmariner/rbac-server"},"helm-values.internalGrpcPort":{"description":"The GRPC port number for the internal service.","type":"number","default":8082},"helm-values.livenessProbe":{"type":"object","properties":{"enabled":{"$ref":"#/$defs/helm-values.livenessProbe.enabled"},"failureThreshold":{"$ref":"#/$defs/helm-values.livenessProbe.failureThreshold"},"initialDelaySeconds":{"$ref":"#/$defs/helm-values.livenessProbe.initialDelaySeconds"},"periodSeconds":{"$ref":"#/$defs/helm-values.livenessProbe.periodSeconds"},"successThreshold":{"$ref":"#/$defs/helm-values.livenessProbe.successThreshold"},"timeoutSeconds":{"$ref":"#/$defs/helm-values.livenessProbe.timeoutSeconds"}},"additionalProperties":false},"helm-values.livenessProbe.enabled":{"description":"Specify whether to enable the liveness probe.","type":"boolean","default":true},"helm-values.livenessProbe.failureThreshold":{"description":"After a probe fails `failureThreshold` times in a row, Kubernetes considers that the overall check has failed: the container is not ready/healthy/live.","type":"number","default":5},"helm-values.livenessProbe.initialDelaySeconds":{"description":"Number of seconds after the container has started before startup, liveness or readiness probes are initiated.","type":"number","default":3},"helm-values.livenessProbe.periodSeconds":{"description":"How often (in seconds) to perform the probe. Default to 10 seconds.","type":"number","default":10},"helm-values.livenessProbe.successThreshold":{"description":"Minimum consecutive successes for the probe to be considered successful after having failed.","type":"number","default":1},"helm-values.livenessProbe.timeoutSeconds":{"description":"Number of seconds after which the probe times out.","type":"number","default":15},"helm-values.monitoringPort":{"description":"The HTTP port number for the inference metrics serving.","type":"number","default":8083},"helm-values.nameOverride":{"description":"Override the \"rbac-server.name\" value, which is used to annotate some of the resources that are created by this Chart (using \"app.kubernetes.io/name\").","type":"string"},"helm-values.nodeSelector":{"description":"The nodeSelector on Pods tells Kubernetes to schedule Pods on the nodes with matching labels. For more information, see [Assigning Pods to Nodes](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/).","type":"object"},"helm-values.podAnnotations":{"description":"Optional additional annotations to add to the Deployment Pods.","type":"object"},"helm-values.podSecurityContext":{"description":"Security Context for the rbac-server pod.\nFor more information, see [Configure a Security Context for a Pod or Container](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/).","type":"object","default":{"fsGroup":2000}},"helm-values.replicaCount":{"description":"The number of replicas for the rbac-server Deployment.","type":"number","default":1},"helm-values.resources":{"description":"Resources to provide to the rbac-server pod.\nFor more information, see [Resource Management for Pods and Containers](https://kubernetes.io/docs/concepts/configuration/manage-resources-Containers/).\n\nFor example:\nrequests:\n  cpu: 10m\n  memory: 32Mi","type":"object","default":{"limits":{"cpu":"250m"},"requests":{"cpu":"250m","memory":"500Mi"}}},"helm-values.roleScopesMap":{"description":"Map a role name to a list of scopes.","type":"object","default":{"organizationOwner":["api.model.read","api.model.write","api.fine_tuning.jobs.read","api.fine_tuning.jobs.write","api.workspaces.notebooks.read","api.workspaces.notebooks.write","api.batch.jobs.read","api.batch.jobs.write","api.files.read","api.files.write","api.vector-stores.read","api.vector-stores.write","api.clusters.read","api.clusters.write","api.selfuser.read","api.selfuser.write","api.api_usages.read","api.api_usages.write"],"projectMember":["api.model.read","api.model.write","api.fine_tuning.jobs.read","api.fine_tuning.jobs.write","api.workspaces.notebooks.read","api.workspaces.notebooks.write","api.batch.jobs.read","api.batch.jobs.write","api.files.read","api.files.write","api.vector-stores.read","api.vector-stores.write","api.selfuser.read","api.selfuser.write","api.api_usages.read","api.api_usages.write"],"projectOwner":["api.model.read","api.model.write","api.fine_tuning.jobs.read","api.fine_tuning.jobs.write","api.workspaces.notebooks.read","api.workspaces.notebooks.write","api.batch.jobs.read","api.batch.jobs.write","api.files.read","api.files.write","api.vector-stores.read","api.vector-stores.write","api.selfuser.read","api.selfuser.write","api.api_usages.read","api.api_usages.write"],"tenantSystem":["api.clusters.read","api.fine_tuning.jobs.read","api.fine_tuning.jobs.write","api.k8s.clusterscope.read","api.k8s.namespaced.write"]}},"helm-values.securityContext":{"description":"Security Context for the rbac-server container.\nFor more information, see [Configure a Security Context for a Pod or Container](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/).","type":"object","default":{"capabilities":{"drop":["ALL"]},"readOnlyRootFilesystem":true,"runAsNonRoot":true,"runAsUser":1000}},"helm-values.tolerations":{"description":"A list of Kubernetes Tolerations, if required.\nFor more information, see [Taints and Tolerations](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/).\n\nFor example:\ntolerations:\n- key: foo.bar.com/role\n  operator: Equal\n  value: master\n  effect: NoSchedule","type":"array","items":{}},"helm-values.version":{"description":"Override the container image tag by setting this variable. If no value is set, the chart's appVersion will be used.","type":"string"},"helm-values.volumeMounts":{"description":"Additional volume mounts to add to the rbac-server container. For more information, see [Volumes](https://kubernetes.io/docs/concepts/storage/volumes/).","type":"array","items":{}},"helm-values.volumes":{"description":"Additional volumes to add to the rbac-server pod.\nFor more information, see [Volumes](https://kubernetes.io/docs/concepts/storage/volumes/).","type":"array","items":{}}}}
